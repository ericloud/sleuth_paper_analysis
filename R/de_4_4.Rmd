---
title: "Differential expression simulation (4 vs 4)"
output:
    html_document:
        toc: true
---

Note: Run all the stuff in `de_4_4.R` first

```{r}
library("sleuth")
library("data.table")
library("ggplot2")
library("xtable")
```

## Framework

- Fit abundance estimation using RSEM on a GEUVADIS sample
- Simulate DE by doing the following:
  - Randomly select 20% of the "valid" transcripts to be DE
    - "valid" transcripts are transcripts with true counts > 5
  - Of the DE transcripts, randomly select 80% to be up regulated (same as
    Li and Tibshirani 2012)
    - Fold change is drawn from $\exp(N(0, 1))$
  - Set dispersion to be 1 / (mean expression / 3)
    - need to revisit this
  - Simulate from a negative binomial

### Simulation properties

Visualizing the mean/variance relationship

```{r cache=TRUE}
ggplot(de_truth, aes(counts, counts + dispersion * counts ^ 2)) +
  geom_point(alpha = 0.2) +
  scale_x_log10() +
  scale_y_log10()
```

```{r}
de_truth %>%
  summarise(
    n_valid_trans = sum(valid_trans),
    n_is_de = sum(is_de),
    n_down = sum(fold_change < 1),
    n_up = sum(fold_change > 1)
    )
```


# kallisto performance

Load the truth

```{r,cache=TRUE}
counts_true <- read.table("../data/de_4_4/counts.txt", header = TRUE,
  stringsAsFactors
  = FALSE)
```

```{r}
#' Convert counts to a proper "oracle"
#' @param counts a counts vector
#' @param target_id transcript name labels
#' @param de_data a \code{data.frame}
counts_to_oracle <- function(counts, target_id, de_data) {
  out <- data.frame(counts = counts, target_id = target_id,
    stringsAsFactors = FALSE)
  de_data %>%
    select(target_id, eff_len) %>%
    inner_join(out, by = c("target_id")) %>%
    mutate(tpm = counts_to_tpm(counts, eff_len))
}
```

```{r cache=TRUE}
de_oracle <- lapply(counts_true[1:8], counts_to_oracle, counts_true["target_id"],
  de_truth)
```

## condition A (4 reps)

```{r,cache=TRUE,echo=FALSE}
mr_a <- lapply(1:4,
  function(i)
  {
    merge_results(
      list(s_o$kal[[i]]$abundance),
      c("kallisto"),
      de_oracle[[i]]
      )
  })
```

```{r,cache=TRUE,echo=FALSE}
cor_a <- lapply(mr_a,
  function(res)
  {
    compute_cor_oracle(res)$est_counts
  }) %>%
    rbind_all()
```

Print a pretty table:

```{r results="asis"}
cor_a %>%
    xtable(digits = 6) %>%
    print(type = "html")
```

### Filtered summary

Do a filtered summary like RSEM

```{r,cache=TRUE}
a_summary <- lapply(mr_a,
  function(res)
  {
    filtered_summary(res, tpm_oracle >= 1.0)$est_counts
  }) %>%
    rbind_all()
```

```{r,results="asis"}
a_summary %>%
  xtable(digits = 6) %>%
  print(type = "html")
```

## condition B (4 reps)

```{r,cache=TRUE,echo=FALSE}
mr_b <- lapply(5:8,
  function(i)
  {
    merge_results(
      list(s_o$kal[[i]]$abundance),
      c("kallisto"),
      de_oracle[[i]]
      )
  })
```

```{r,cache=TRUE,echo=FALSE}
cor_b <- lapply(mr_b,
  function(res)
  {
    compute_cor_oracle(res)$est_counts
  }) %>%
    rbind_all()
```

Print a pretty table:

```{r results="asis"}
cor_b %>%
    xtable(digits = 6) %>%
    print(type = "html")
```

### Filtered summary

Do a filtered summary like RSEM

```{r,cache=TRUE}
b_summary <- lapply(mr_b,
  function(res)
  {
    filtered_summary(res, tpm_oracle >= 1.0)$est_counts
  }) %>%
    rbind_all()
```
```{r,results="asis"}
b_summary %>%
  xtable(digits = 6) %>%
  print(type = "html")
```

# sleuth

## Fold change estimates

Estimated fold change vs the true fold change

```{r,cache=TRUE}
ggplot(valid_obs, aes(conditionb, log(fold_change), colour = is_de)) +
  geom_point(aes(group = valid_trans), alpha = 0.2) +
  scale_colour_manual(values = c("red", "black")) +
  geom_abline(slope = 1, intercept = 0) +
  geom_smooth(method = "lm", colour = "blue") +
  xlim(-10, 10) +
  ylim(-2, 2)
```

Do the same thing with bootstrap:

```{r,cache=TRUE}
ggplot(valid_obs, aes(bs_mean_conditionb, log(fold_change), colour = is_de)) +
  geom_point(aes(group = valid_trans), alpha = 0.2) +
  scale_colour_manual(values = c("red", "black")) +
  geom_abline(slope = 1, intercept = 0) +
  geom_smooth(method = "lm", colour = "blue") +
  xlim(-10, 10) +
  ylim(-2, 2)
```

They look pretty similar, but the observations do slightly better as one might
hope:

```{r}
valid_obs %>%
  summarise(
    mpe_est = median(abs(
        sleuth:::scaled_error(conditionb, log(fold_change))), na.rm = TRUE),
    mpe_bs = median(abs(
        sleuth:::scaled_error(bs_mean_conditionb, log(fold_change))), na.rm = TRUE)
)
```

Let's look at the distribution of things we're screwing up on that are NOT
differentially expressed:

```{r,cache=TRUE}
filter(valid_obs, !is_de) %>%
  ggplot(aes(conditionb, y = ..density..)) +
  geom_vline(xintercept = 0, colour = "red") +
  geom_histogram(binwidth = 0.05) +
  xlim(-4, 4)
```

I'm kind of suspicious of where the peak is. I'm going to look into
incorporating the size factor into the GLM estimation procedure (they do in
DESeq)

## GLM theory $\hat{\text{se}}(\beta_1)$ vs bootstrap estimate

```{r,cache=TRUE}
ggplot(valid_obs,
  aes(se_conditionb, bs_se_conditionb)) +
  geom_point(alpha = 0.15) +
  xlim(0, 0.5) +
  ylim(0, 0.5) +
  geom_abline(intercept = 0, slope = 1)
```

Segregate based on if (DE?, valid trans?)

```{r,cache=TRUE,fig.width=8,fig.height=12}
ggplot(valid_obs,
  aes(se_conditionb, bs_se_conditionb)) +
  geom_point(alpha = 0.15) +
  xlim(0, 0.5) +
  ylim(0, 0.5) +
  facet_wrap(~ is_de + valid_trans, nrow = 3) +
  geom_abline(intercept = 0, slope = 1)
```

Anything close to the $y = x$ is kind of concerning...


#### When is bootstrap error > GLM error?

Now that we have these estimates, we can take a look at how we're doing on the
particular transcripts to see if it is reflective of how we are doing with the
oracle.

Compute the median scaled err and percent error for each transcript

```{r,cache=TRUE}
trans_err <- lapply(c(mr_a, mr_b),
  function(x)
  {
    filtered_no_summary(x)$est_counts
  }) %>%
    rbind_all()

trans_err_summary <- trans_err %>%
  group_by(target_id) %>%
  summarise(
    med_scaled_err = median(abs(scaled_err), na.rm = TRUE),
    med_per_err = median(abs(per_err), na.rm = TRUE)
    )
```

Add in the columns:

```{r,cache=TRUE}
valid_obs <- valid_obs %>%
  inner_join(trans_err_summary, by = c("target_id"))
```


Now, let's look at the distribution of transcript level error when bootstrap
error > GLM error vs the rest.

First, let's look at scaled error:

```{r,cache=TRUE}
valid_obs %>%
  mutate(bs_err_gr = bs_se_conditionb >= se_conditionb) %>%
  ggplot(aes(med_scaled_err, y = ..density..)) +
    geom_histogram() +
    facet_wrap(~bs_err_gr, ncol = 1)
```

Percent error:

```{r,cache=TRUE}
valid_obs %>%
  mutate(bs_err_gr = bs_se_conditionb >= se_conditionb) %>%
  ggplot(aes(med_per_err, y = ..density..)) +
    geom_histogram(binwidth=0.05) +
    xlim(0, 3) +
    facet_wrap(~bs_err_gr, ncol = 1)
```

Let's look at the ratio of the BS error to GLM error:

```{r,cache=TRUE}
valid_obs <- valid_obs %>%
  mutate(se_ratio = bs_se_conditionb / se_conditionb)
```

```{r,cache=TRUE}
ggplot(valid_obs, aes(se_ratio, med_scaled_err)) +
  geom_point(alpha = 0.05) +
  xlim(0, 200) +
  ylim(0, 2)
```

Let's zoom in a bit more...

```{r,cache=TRUE}
valid_obs %>%
  ggplot(aes(se_ratio, med_scaled_err)) +
    geom_point(alpha = 0.05) +
    xlim(0, 2.5) +
    ylim(0, 1)
```

Even more...

```{r,cache=TRUE}
valid_obs %>%
  ggplot(aes(se_ratio, med_scaled_err)) +
    geom_point(alpha = 0.05) +
    xlim(0, 1.25) +
    ylim(0, 0.25)
```

How well are these things correlated?

```{r}
valid_obs %>%
  summarise(cor(se_ratio, med_scaled_err, use = "complete.obs"))
```

## Dispersion estimates

Note that the dispersion in the gamma plays a different role than in the NB
($\phi \mu^2$ vs $\mu + \alpha \mu^2$)

```{r,cache=TRUE}
valid_obs %>%
  ggplot(aes(counts, dispersion)) +
    geom_point(alpha = 0.05) +
    xlim(0, 1000)
```

```{r,cache=TRUE}
de_truth %>%
  select(target_id, nb_dispersion = dispersion) %>%
  inner_join(valid_obs, by = c("target_id")) %>%
  ggplot(aes(nb_dispersion, dispersion)) +
    geom_point(alpha = 0.05) +
    xlim(0, 1) +
    ylim(0, 1)
```
